# AI Governance Project

**Version:** v0.4  
**Status:** Draft — Architecture Phase  
**Lead:** Federico Blanco Sánchez-Llanos  
**Date:** February 20, 2026

---

## Executive Framing

Advanced AI systems are rapidly evolving from assistive tools into persistent, economically active agents. Existing governance approaches often treat these systems as a single regulatory category, creating structural blind spots.

The AI Governance Project develops a **capability-tiered governance framework** that aligns oversight and enforcement architecture with system autonomy, persistence, planning capacity, and economic agency.

The objective is not reactive regulation — but structural synchronization between capability expansion and governance maturity.

This repository develops that architecture step by step.

---

## Premise

The term “AI” currently collapses fundamentally different system types into a single regulatory category.

Stateless predictive tools, enterprise workflow agents, economically active autonomous systems, sovereign-scale compute deployments, and decentralized rogue actors cannot coherently share the same governance regime.

Effective governance must map to **capability — not branding.**

As capability growth accelerates, governance must evolve proportionally.  
The question is not whether advanced AI systems will emerge — but whether enforcement infrastructure matures alongside them.

---

## Structure of the Research Series

### [Note I — The AI Agent Spectrum](./notes/note-01-ai-agent-spectrum.md)

Introduces a capability-based classification of AI systems.

**Core thesis:**  
Governance must be capability-tiered.

The note defines a spectrum based on:

- Autonomy  
- Persistence  
- Goal formation  
- Economic participation  
- Infrastructure access  
- Identity continuity  

It outlines differentiated governance modes appropriate to each class of system.

### [Note II — From Agent Spectrum to Governance Architecture](./notes/note-02-from-agent-spectrum-to-governance-architecture.md)

Builds on the spectrum model and introduces structural implications.

**Core thesis:**  
Governance must move from declarative regulation to infrastructural architecture.

This note explores:

- Why uniform regulation fails  
- How governance attaches to leverage points  
- The emerging role of compute, energy, identity, and infrastructure  
- The concept of enforcement as a system layer  

It introduces the idea that enforcement in AI ecosystems may increasingly become infrastructural and partially autonomous.

### [Note III — Capability-Tiered Governance & Enforcement Architecture](./notes/note-03-capability-tiered-governance-enforcement.md)

Formalizes the capability spectrum and establishes enforcement as an architectural necessity.

**Core thesis:**  
As AI systems gain persistence, planning capacity, and economic agency, governance must migrate from policy toward embedded runtime architecture.

#### Four-Tier Capability Spectrum

| Tier   | System Type                          | Core Traits                                          | Governance Mode                          |
|--------|--------------------------------------|------------------------------------------------------|------------------------------------------|
| Tier 1 | Assistive Systems                    | Stateless, human-directed                            | Disclosure, usage norms                  |
| Tier 2 | Hybrid Distributed Agency Systems    | Persistent memory, bounded workflows                 | Auditability, traceability               |
| Tier 3 | Autonomous Operational Agents        | Persistent identity, adaptive planning               | Runtime constraint enforcement           |
| Tier 4 | Autonomous Economic Agents           | Capital allocation, contracts, market participation  | Infrastructure-level gating & verification |

#### Governance Maturity Alignment

Each capability tier requires a corresponding maturity level in governance architecture.

Governance layers include:

- Policy layer  
- Institutional oversight layer  
- Runtime constraint layer  
- Verification layer  
- Enforcement node networks  

#### Enforcement as Architecture

As AI systems gain planning, persistence, and economic agency, enforcement cannot remain exclusively declarative or post-hoc.

It must increasingly embed into:

- Runtime constraint systems  
- Verification architectures  
- Infrastructure layers  
- Compute and resource gating regimes  

**Conceptual enforcement topology:**

**Agent Layer → Constraint Layer → Verification Layer → Enforcement Node Network**

AI governance becomes a synchronization challenge between capability acceleration and enforcement maturity.

### [Note IV — Enforcement Primitives & Runtime Constraint Architecture](./notes/note-04-enforcement-primitives.md)

Formalizes the enforcement primitives and introduces **Compute Gating** as the core sovereignty mechanism and architectural hinge.

**Core thesis:**  
Policy does not scale at machine speed. Infrastructure does. Governance must therefore embed directly into runtime systems through interoperable enforcement primitives, with Compute Gating anchoring sovereign control over capability expansion.

This note defines:

- A formal taxonomy of seven enforcement primitives  
- The Compute Gating function, regimes by capability tier, and distributed topologies  
- Geopolitical leverage, failure modes, and design principles  
- The structural reality that sovereignty in advanced AI systems is ultimately defined by who controls scalable compute access  

It positions Compute Gating as the enforceable link between capability acceleration and governance maturity.

---

## Direction of Inquiry

Future work will explore:

- Enforcement as a formal governance layer  
- Autonomous enforcement agents  
- Resource gating and compute access regimes  
- Sovereign compute infrastructure  
- Multilateral vs national governance architectures  
- Power concentration risks in enforcement systems  
- Governance of the enforcers  

---

## Risks & Structural Tensions

Any enforcement architecture introduces structural tradeoffs. This project explicitly examines:

- Centralization and concentration risk  
- Regulatory capture risk  
- Sovereign fragmentation  
- Innovation suppression through over-constraint  
- Governance infrastructure becoming geopolitical leverage  

These risks are not peripheral — they are integral to the design problem.

---

## Project Approach

This project proceeds methodically:

1. Map the terrain  
2. Clarify categories  
3. Identify leverage points  
4. Develop structural models  
5. Articulate strategic implications  

Analytical foundations precede policy positioning.

---

## Non-Goals

This repository does not:

- Propose a global centralized AI authority  
- Advocate premature capability caps  
- Promote broad surveillance expansion  
- Restrict open research by default  
- Assume a specific geopolitical governance model  

The work focuses on architectural clarity — not prescriptive overreach.

---

## Working Assumptions

These assumptions are examined, not asserted:

- AI systems will increase in autonomy and persistence  
- Economically active agents will proliferate  
- Compute concentration will have geopolitical implications  
- Governance will increasingly attach to infrastructure  
- Enforcement cannot remain purely declarative  

---

## Initiative Position

This repository represents early-stage work toward a capability-tiered governance standard for advanced AI systems.

It aims to complement — not replace — existing frameworks such as:

- ISO/IEC JTC 1/SC 42  
- NIST AI Risk Management Framework  

The contribution is structural: capability-tiered alignment and enforcement architecture modeling.

---

## Objective

The objective is to:

- Formalize classification frameworks  
- Define enforcement architecture requirements  
- Develop interoperable governance primitives  
- Contribute to emerging standards discourse  

This is an architectural exploration phase.

Future iterations may include:

- Formal proposals  
- Draft technical specifications  
- Reference models  
- Collaborative contributions  

---

## Audience

- Governance advisors  
- Policy designers  
- Infrastructure architects  
- National security analysts  
- Institutional leaders  
- AI systems designers  

---

## Collaboration & Engagement

The AI Governance Project welcomes substantive engagement from researchers, institutional leaders, and practitioners working at the intersection of AI systems design and governance.

Engagement should focus on architectural, enforcement-level, or structural governance questions aligned with the framework.

We particularly welcome:

- Parallel research on enforcement primitives or runtime constraint systems  
- Feedback on the four-tier capability spectrum  
- Proposals for verifiable identity models or cross-agent verification topologies  
- Insights from sovereign compute, economic throttling, or multilateral governance perspectives  

Serious, focused contributions help advance this work from conceptual foundations toward interoperable standards.

---

## How to Engage

If your work directly intersects with capability-tiered governance, enforcement architectures, identity continuity, jurisdictional awareness, interoperable enforcement nodes, or related topics:

→ Open an issue describing the overlap or proposed contribution.

For deeper discussion, formal critique, collaborative refinement, or potential standards alignment:

→ Contact the project lead directly.

Please include context from specific notes, principles, or sections to ensure focused dialogue.

---

## Contact

**Federico Blanco Sánchez-Llanos**

Email: [fsllanos@gmail.com](mailto:fsllanos@gmail.com)  
LinkedIn: [https://www.linkedin.com/in/fedblanco](https://www.linkedin.com/in/fedblanco)

We aim to respond thoughtfully to substantive outreach within a reasonable timeframe.

---

## License

This work is licensed under the Creative Commons Attribution–NonCommercial 4.0 International License (CC BY-NC 4.0).

Commercial use, institutional embedding, or derivative advisory applications require explicit permission.

---
